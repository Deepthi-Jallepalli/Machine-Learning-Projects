{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a neural network model from scratch to classify the Iris data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Iris Data Set and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "iris = iris.sample(frac=1).reset_index(drop=True)\n",
    "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "X = np.array(X)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "Y = iris.Species\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Training data Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size = 0.2,random_state=0)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network building : Create 3 layers: 1 Input(4 units) ,1 hidden (parameter passed during execution) and 1 Output (3 units) .\n",
    "Inputs = length and widths of the species\n",
    "Output = Target Classes \n",
    "\n",
    "w1 is weight connecting Input and the hidden layer. Each node in input layer connects to each node in the hidden layer.\n",
    "w2 are the weights of connections between hidden layer and output layer.\n",
    "\n",
    "Initial weights: Weight are randomized between -0.05 and 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Training : Train the network by updating the weights using backpropogation. This is the crux of the network. The layers are fed forward using sigmoid activation function. The weighs are then updated based on error using gradient descent. Set the training rate to 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=100, nodes=[],lr = 0.01):\n",
    "    hidden_layers = len(nodes) - 1\n",
    "    weights = InitializeWeights(nodes)\n",
    "\n",
    "    for epochs in range(1, epochs+1):\n",
    "        weights = Train(X_train, Y_train, lr, weights)\n",
    "        if(epochs % 20 == 0):\n",
    "            print(\"epochs {}\".format(epochs))\n",
    "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
    "            if X_val.any():\n",
    "                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeWeights(nodes):\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        w = [[np.random.uniform(-0.05, 0.05) for k in range(nodes[i-1] + 1)]\n",
    "              for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(w))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardPropagation(x, weights, layers):\n",
    "    activations, layer_input = [x], x\n",
    "    for j in range(layers):\n",
    "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
    "        activations.append(activation)\n",
    "        layer_input = np.append(1, activation) # with bias\n",
    "    \n",
    "    return activations\n",
    "\n",
    "def BackPropagation(y, activations, weights, layers):\n",
    "    outputFinal = activations[-1]\n",
    "    error = np.matrix(y - outputFinal)\n",
    "    \n",
    "    for j in range(layers, 0, -1):\n",
    "        currActivation = activations[j]\n",
    "        \n",
    "        if(j > 1):\n",
    "            prevActivation = np.append(1, activations[j-1])\n",
    "        else:\n",
    "            prevActivation = activations[0]\n",
    "        \n",
    "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
    "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
    "\n",
    "        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
    "        error = np.dot(delta, w)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model:\n",
    "def Train(X, Y, lr, weights):\n",
    "    layers = len(weights)\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], Y[i]\n",
    "        x = np.matrix(np.append(1, x))\n",
    "        \n",
    "        activations = ForwardPropagation(x, weights, layers)\n",
    "        weights = BackPropagation(y, activations, weights, layers)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def SigmoidDerivative(x):\n",
    "    return np.multiply(x, 1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Predictaion and Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1, item)\n",
    "    \n",
    "    activations = ForwardPropagation(item, weights, layers)   \n",
    "    outputFinal = activations[-1].A1\n",
    "    index = FindMaxActivation(outputFinal)\n",
    "    y = [0 for i in range(len(outputFinal))]\n",
    "    y[index] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def FindMaxActivation(output):\n",
    "    m, index = output[0], 0\n",
    "    for i in range(1, len(output)):\n",
    "        if(output[i] > m):\n",
    "            m, index = output[i], i\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(X, Y, weights):\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], list(Y[i])\n",
    "        guess = Predict(x, weights)\n",
    "\n",
    "        if(y == guess):\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 20\n",
      "Training Accuracy:0.3425925925925926\n",
      "Validation Accuracy:0.25\n",
      "epochs 40\n",
      "Training Accuracy:0.3425925925925926\n",
      "Validation Accuracy:0.25\n",
      "epochs 60\n",
      "Training Accuracy:0.3425925925925926\n",
      "Validation Accuracy:0.25\n",
      "epochs 80\n",
      "Training Accuracy:0.3425925925925926\n",
      "Validation Accuracy:0.25\n",
      "epochs 100\n",
      "Training Accuracy:0.3425925925925926\n",
      "Validation Accuracy:0.25\n",
      "Accuracy on test data: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "i = len(X[0]) # Number of input units\n",
    "o = len(Y[0]) # Number of output units\n",
    "\n",
    "layers = [i,5,9,10,o] # Number of units in hidden layer\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Train the network for the specified number of iterations at learning rate 0.01.\n",
    "\n",
    "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val,epochs=epochs, nodes=layers, lr=lr);\n",
    "print(\"Accuracy on test data: {}\".format(Accuracy(X_test, Y_test, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the number of hidden units affect the final accuracy on the test data?\n",
    "observation : Accuracy is high when no.of hiden layers are increased that means ,model is overfitting the data\n",
    "\n",
    "2. How does it affect the number of epochs needed for training to converge?\n",
    "observation: As epochs increase it will result in smooth curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference for the above work\n",
    "#http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "#http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "#https://selbydavid.com/2018/01/09/neural-network/\n",
    "#https://towardsdatascience.com/neural-network-on-iris-data-4e99601a42c8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
